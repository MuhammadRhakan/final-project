{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "959556ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import time\n",
    "import math\n",
    "import spacy\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from sklearn.preprocessing import StandardScaler, normalize, OneHotEncoder\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "763d629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "course = pd.read_csv('Course_info.csv')\n",
    "course = course[course['language'].isin({'English', 'Indonesian'})].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f379a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attributes(data, shift='avg_rating'):\n",
    "  categorical = []\n",
    "  numerical = []\n",
    "\n",
    "  for i, cat in enumerate(data.select_dtypes(include = ['object', 'bool']).columns.values):\n",
    "    categorical.append(cat)\n",
    "  categorical.append(shift)\n",
    "\n",
    "  for i, num in enumerate(data.select_dtypes(include = 'number').drop(columns='id').columns.values):\n",
    "    if num != shift:\n",
    "      numerical.append(num)\n",
    "\n",
    "  return categorical, numerical\n",
    "\n",
    "def outliers_handling(data, features, alpha=0.1):\n",
    "  outliers_indices = set()\n",
    "\n",
    "  for col in features:\n",
    "    upper = data[col].quantile(1-alpha)\n",
    "    lower = data[col].quantile(alpha)\n",
    "\n",
    "    outside = data[(data[col] < lower) | (data[col] > upper)]\n",
    "    outliers_indices.update(outside.index)\n",
    "\n",
    "  trim = data.drop(index=outliers_indices)\n",
    "  log_trim = trim.copy()\n",
    "  log_trim[features] = np.log1p(trim[features])\n",
    "\n",
    "  return trim, log_trim\n",
    "\n",
    "def features_type(data):\n",
    "  return {\n",
    "      'semantic': ['title', 'headline'],\n",
    "      'nominal': ['is_paid', 'category', 'subcategory'],\n",
    "      'datetime': ['published_time', 'last_update_date'],\n",
    "      'high_cardinal': 'instructor_name',\n",
    "      'ordinal': 'avg_rating'}\n",
    "\n",
    "def calc_smoothed_instructor_rating(data, feature, rating='avg_rating', subscriber='num_subscribers', weight=50):\n",
    "  data['engagement'] = data[rating] * data[subscriber]\n",
    "\n",
    "  instructor_stats = data.groupby(feature).agg(\n",
    "      total_rating=('engagement', 'sum'),\n",
    "      total_subs=(subscriber, 'sum'))\n",
    "\n",
    "  instructor_stats['weighted_avg'] = instructor_stats['total_rating'] / instructor_stats['total_subs']\n",
    "  global_avg = data['engagement'].sum() / data[subscriber].sum()\n",
    "  instructor_stats['smoothed'] = (\n",
    "      (instructor_stats['total_subs'] * instructor_stats['weighted_avg'] + weight * global_avg) /\n",
    "      (instructor_stats['total_subs'] + weight))\n",
    "\n",
    "  data['instructor_score'] = data[feature].map(instructor_stats['smoothed'])\n",
    "  data[['avg_rating', 'instructor_score']] = data[['avg_rating', 'instructor_score']].astype('int64')\n",
    "\n",
    "  return data[['avg_rating', 'instructor_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88a62793",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical, numerical = attributes(course)\n",
    "course_clean, course_clean_scaled = outliers_handling(course, numerical)\n",
    "types = features_type(course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec082c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_preprocessing(data, features, n_neighbors=10):\n",
    "  text = data.copy()\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  stemmer = PorterStemmer()\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "  english_features = text[features].apply(lambda col: col.apply(lambda text: text.lower()))\n",
    "\n",
    "  for col in features:\n",
    "    english_features[col] = english_features[col].apply(lambda text: nltk.word_tokenize(text))\n",
    "    english_features[col] = english_features[col].apply(lambda text: [word for word in text if word.lower() not in stop_words])\n",
    "    # english_features[col] = english_features[col].apply(lambda text: [stemmer.stem(word) for word in text])\n",
    "    english_features[col] = english_features[col].apply(lambda text: [lemmatizer.lemmatize(word) for word in text if word.isalpha()])\n",
    "    english_features[col] = english_features[col].apply(lambda text: ' '.join(text))\n",
    "\n",
    "  combined_text = english_features.apply(lambda row: ' '.join(row), axis=1)\n",
    "\n",
    "  vectorizer = TfidfVectorizer(max_features=5000, min_df=3, max_df=0.85, ngram_range=(1,2), use_idf=True, smooth_idf=True)\n",
    "  tfidf_matrix = vectorizer.fit_transform(combined_text)\n",
    "\n",
    "  knn = NearestNeighbors(n_neighbors=n_neighbors+1, metric='cosine')\n",
    "  knn.fit(tfidf_matrix)\n",
    "  distances, indices = knn.kneighbors(tfidf_matrix)\n",
    "  cosine_similarities = 1 - distances\n",
    "\n",
    "  return cosine_similarities[:, 1:], indices[:, 1:]\n",
    "\n",
    "\n",
    "def numerical_preprocessing(data, features, n_neighbors=10):\n",
    "  normalized_data = normalize(data[features])\n",
    "\n",
    "  knn = NearestNeighbors(n_neighbors=n_neighbors+1, metric='euclidean')\n",
    "  knn.fit(normalized_data)\n",
    "  distances, indices = knn.kneighbors(normalized_data)\n",
    "  euclidean_similarities = 1 - distances\n",
    "\n",
    "  return euclidean_similarities[:, 1:], indices[:, 1:]\n",
    "\n",
    "\n",
    "def nominal_preprocessing(data, features, n_neighbors=10):\n",
    "  data = data[features].copy()\n",
    "  categorical = pd.concat([data['is_paid'].astype('uint8'), \n",
    "                           pd.get_dummies(data['category'], prefix='category', dtype='uint8'), \n",
    "                           pd.get_dummies(data['subcategory'], prefix='sub_category', dtype='uint8')],\n",
    "                           axis=1)\n",
    "\n",
    "  pca_result = PCA(n_components=0.95).fit_transform(categorical)\n",
    "  knn = NearestNeighbors(n_neighbors=n_neighbors+1, metric='cosine')\n",
    "  knn.fit(pca_result)\n",
    "  distances, indices = knn.kneighbors(pca_result)\n",
    "  cosine_similarities = 1 - distances\n",
    "\n",
    "  return cosine_similarities[:, 1:], indices[:, 1:]\n",
    "\n",
    "\n",
    "def ordinal_preprocessing(data, n_neighbors=10):\n",
    "  ordinal_data = data.rank(axis=0, method='average')\n",
    "\n",
    "  normalized_data = normalize(ordinal_data, norm='l2', axis=1)\n",
    "  nbrs = NearestNeighbors(n_neighbors=n_neighbors+1, metric='cosine', n_jobs=-1)\n",
    "  nbrs.fit(normalized_data)\n",
    "\n",
    "  distances, indices = nbrs.kneighbors(normalized_data)\n",
    "  cosine_similarities = 1 - distances\n",
    "\n",
    "  return cosine_similarities[:, 1:], indices[:, 1:]\n",
    "\n",
    "\n",
    "def datetime_preprocessing(data, features, due='2022-10-10', decay=0.01, weights=None):\n",
    "  data = data[features].copy()\n",
    "\n",
    "  for col in features:\n",
    "    data[col] = pd.to_datetime(data[col]).dt.tz_localize(None)\n",
    "    col_name = f\"{col}_duration\"\n",
    "    data[col_name] = (pd.to_datetime(due) - data[col]).dt.days\n",
    "    data[col_name] = data[col_name].apply(lambda x: np.exp(-decay * x))\n",
    "\n",
    "  decay_cols = [f\"{col}_duration\" for col in features]\n",
    "  date_matrix = data[decay_cols].values\n",
    "\n",
    "  if weights:\n",
    "      for i, col in enumerate(decay_cols):\n",
    "          date_matrix[:, i] *= weights.get(col, 1.0)\n",
    "\n",
    "  model = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "  model.fit(date_matrix)\n",
    "  distances, indices = model.kneighbors(date_matrix)\n",
    "  cosine_similarities = 1 - distances\n",
    "\n",
    "  return cosine_similarities[:, 1:], indices[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d36e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_semantic, _ = semantic_preprocessing(course_clean, types['semantic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c1ba70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_nominal, _ = nominal_preprocessing(course_clean, types['nominal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5325c7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_numeric, _ = numerical_preprocessing(course_clean_scaled, features=numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "621c875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_mod = calc_smoothed_instructor_rating(course_clean_scaled, types['high_cardinal'])\n",
    "G_ordinal, _ = ordinal_preprocessing(ordinal_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e110d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_datetime, _ = datetime_preprocessing(course_clean, types['datetime'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
